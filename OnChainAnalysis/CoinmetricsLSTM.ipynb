{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f454d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (5.26.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.71.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Using cached numpy-2.1.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.13.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Using cached optree-0.15.0-cp311-cp311-win_amd64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.19.0-cp311-cp311-win_amd64.whl (375.9 MB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.71.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "Downloading h5py-3.13.0-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.8/3.0 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 8.7 MB/s eta 0:00:00\n",
      "Using cached keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.6/26.4 MB 7.0 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 2.1/26.4 MB 5.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.1/26.4 MB 5.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.5/26.4 MB 6.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 8.1/26.4 MB 7.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 10.2/26.4 MB 7.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 12.3/26.4 MB 8.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 14.4/26.4 MB 8.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.5/26.4 MB 8.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 21.0/26.4 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.8/26.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.9/26.4 MB 8.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.4 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 8.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl (209 kB)\n",
      "Downloading numpy-2.1.3-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.9 MB 2.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.0/12.9 MB 2.8 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.3/12.9 MB 2.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 2.2 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.1/12.9 MB 2.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.4/12.9 MB 2.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.9/12.9 MB 2.0 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 3.1/12.9 MB 1.9 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 1.9 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 3.7/12.9 MB 1.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.9/12.9 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 3.9/12.9 MB 1.7 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 4.2/12.9 MB 1.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 4.2/12.9 MB 1.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 4.5/12.9 MB 1.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 4.5/12.9 MB 1.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 4.5/12.9 MB 1.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 4.5/12.9 MB 1.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 4.5/12.9 MB 1.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 4.5/12.9 MB 1.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 4.7/12.9 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.7/12.9 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.7/12.9 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.7/12.9 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.7/12.9 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 4.7/12.9 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 5.0/12.9 MB 885.6 kB/s eta 0:00:09\n",
      "   --------------- ------------------------ 5.0/12.9 MB 885.6 kB/s eta 0:00:09\n",
      "   --------------- ------------------------ 5.0/12.9 MB 885.6 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 817.3 kB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 817.3 kB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 817.3 kB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 5.5/12.9 MB 773.2 kB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 5.5/12.9 MB 773.2 kB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 5.5/12.9 MB 773.2 kB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 5.8/12.9 MB 751.2 kB/s eta 0:00:10\n",
      "   ----------------- ---------------------- 5.8/12.9 MB 751.2 kB/s eta 0:00:10\n",
      "   ------------------ --------------------- 6.0/12.9 MB 736.7 kB/s eta 0:00:10\n",
      "   ------------------ --------------------- 6.0/12.9 MB 736.7 kB/s eta 0:00:10\n",
      "   ------------------ --------------------- 6.0/12.9 MB 736.7 kB/s eta 0:00:10\n",
      "   ------------------- -------------------- 6.3/12.9 MB 729.4 kB/s eta 0:00:10\n",
      "   ------------------- -------------------- 6.3/12.9 MB 729.4 kB/s eta 0:00:10\n",
      "   -------------------- ------------------- 6.6/12.9 MB 724.2 kB/s eta 0:00:09\n",
      "   -------------------- ------------------- 6.6/12.9 MB 724.2 kB/s eta 0:00:09\n",
      "   --------------------- ------------------ 6.8/12.9 MB 719.5 kB/s eta 0:00:09\n",
      "   --------------------- ------------------ 6.8/12.9 MB 719.5 kB/s eta 0:00:09\n",
      "   --------------------- ------------------ 7.1/12.9 MB 712.7 kB/s eta 0:00:09\n",
      "   --------------------- ------------------ 7.1/12.9 MB 712.7 kB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 705.6 kB/s eta 0:00:08\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 705.6 kB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 702.2 kB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 702.2 kB/s eta 0:00:08\n",
      "   ------------------------ --------------- 7.9/12.9 MB 701.0 kB/s eta 0:00:08\n",
      "   ------------------------ --------------- 7.9/12.9 MB 701.0 kB/s eta 0:00:08\n",
      "   ------------------------- -------------- 8.1/12.9 MB 695.2 kB/s eta 0:00:07\n",
      "   ------------------------- -------------- 8.1/12.9 MB 695.2 kB/s eta 0:00:07\n",
      "   ------------------------- -------------- 8.1/12.9 MB 695.2 kB/s eta 0:00:07\n",
      "   ------------------------- -------------- 8.1/12.9 MB 695.2 kB/s eta 0:00:07\n",
      "   ------------------------- -------------- 8.1/12.9 MB 695.2 kB/s eta 0:00:07\n",
      "   ------------------------- -------------- 8.1/12.9 MB 695.2 kB/s eta 0:00:07\n",
      "   ------------------------- -------------- 8.1/12.9 MB 695.2 kB/s eta 0:00:07\n",
      "   -------------------------- ------------- 8.4/12.9 MB 630.4 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.4/12.9 MB 630.4 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.4/12.9 MB 630.4 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.4/12.9 MB 630.4 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.4/12.9 MB 630.4 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.4/12.9 MB 630.4 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.7/12.9 MB 592.6 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.7/12.9 MB 592.6 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.7/12.9 MB 592.6 kB/s eta 0:00:08\n",
      "   -------------------------- ------------- 8.7/12.9 MB 592.6 kB/s eta 0:00:08\n",
      "   --------------------------- ------------ 8.9/12.9 MB 577.9 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 8.9/12.9 MB 577.9 kB/s eta 0:00:07\n",
      "   --------------------------- ------------ 8.9/12.9 MB 577.9 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 9.2/12.9 MB 569.8 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 9.2/12.9 MB 569.8 kB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 9.2/12.9 MB 569.8 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 566.3 kB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 566.3 kB/s eta 0:00:07\n",
      "   ------------------------------ --------- 9.7/12.9 MB 565.0 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 9.7/12.9 MB 565.0 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 10.0/12.9 MB 564.8 kB/s eta 0:00:06\n",
      "   ------------------------------ --------- 10.0/12.9 MB 564.8 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 10.2/12.9 MB 566.2 kB/s eta 0:00:05\n",
      "   ------------------------------- -------- 10.2/12.9 MB 566.2 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 10.5/12.9 MB 568.0 kB/s eta 0:00:05\n",
      "   -------------------------------- ------- 10.5/12.9 MB 568.0 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 10.7/12.9 MB 570.2 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 10.7/12.9 MB 570.2 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 10.7/12.9 MB 570.2 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 11.0/12.9 MB 567.1 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 11.0/12.9 MB 567.1 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 11.0/12.9 MB 567.1 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 11.0/12.9 MB 567.1 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 11.0/12.9 MB 567.1 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 11.3/12.9 MB 550.5 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.3/12.9 MB 550.5 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.3/12.9 MB 550.5 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.3/12.9 MB 550.5 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 538.8 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 538.8 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 538.8 kB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 11.5/12.9 MB 538.8 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 11.8/12.9 MB 532.2 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 11.8/12.9 MB 532.2 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 12.1/12.9 MB 529.8 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 12.1/12.9 MB 529.8 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 12.1/12.9 MB 529.8 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 12.3/12.9 MB 528.6 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 12.3/12.9 MB 528.6 kB/s eta 0:00:02\n",
      "   ---------------------------------------  12.6/12.9 MB 528.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.9 MB 528.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.6/12.9 MB 528.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 526.0 kB/s eta 0:00:00\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "Using cached termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Using cached wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.15.0-cp311-cp311-win_amd64.whl (306 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, numpy, markdown, grpcio, google-pasta, gast, astunparse, tensorboard, ml-dtypes, h5py, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution ~umpy (c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "    WARNING: Skipping numpy as it is not installed.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\tensorflow\\\\compiler\\\\mlir\\\\lite\\\\python\\\\_pywrap_converter_api.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (5.26.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.2-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.71.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Using cached numpy-2.1.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.13.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Using cached optree-0.15.0-cp311-cp311-win_amd64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.19.0-cp311-cp311-win_amd64.whl (375.9 MB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.71.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "Using cached h5py-3.13.0-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "Using cached keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp311-cp311-win_amd64.whl (209 kB)\n",
      "Downloading numpy-2.1.3-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.9 MB 4.8 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.5/12.9 MB 12.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 13.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/12.9 MB 13.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 13.9 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 28.0 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 19.4 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp311-cp311-win_amd64.whl (306 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, numpy, markdown, grpcio, google-pasta, gast, astunparse, tensorboard, ml-dtypes, h5py, keras, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.2\n",
      "    Uninstalling numpy-1.24.2:\n",
      "      Successfully uninstalled numpy-1.24.2\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 keras-3.9.2 libclang-18.1.1 markdown-3.7 ml-dtypes-0.5.1 namex-0.0.8 numpy-2.1.3 opt-einsum-3.4.0 optree-0.15.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-3.0.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.1.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install coinmetrics-api-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb523b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb87a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<coinmetrics.api_client.CoinMetricsClient object at 0x00000240EC912050>\n"
     ]
    }
   ],
   "source": [
    "from coinmetrics.api_client import CoinMetricsClient\n",
    "\n",
    "client = CoinMetricsClient()\n",
    "\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9ff883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'SplyCntCur' - this is for the supply count of the current coin\n",
    "# 'CapMrktCurUSD' - this is for the market capitalization of the current coin\n",
    "# 'PriceUSD' - this is for the price of the current coin\n",
    "# 'TxTfrValAdjUSD' - this is for the adjusted transaction value in USD\n",
    "# 'TxTfrValUSD' - this is for the transaction value in USD  \n",
    "# 'TxTfrCnt' - this is for the transaction count\n",
    "# 'IssContNtv' - this is for the native issuance count\n",
    "# 'IssContPctAnn' - this is for the annual percentage of the issuance count\n",
    "# \n",
    "metrics = client.get_asset_metrics(assets='btc', metrics=['PriceUSD','HashRate','TxTfrCnt','AdrActCnt', 'SplyCur'], start_time=\"2013-01-01\", end_time=\"2023-01-02\", frequency='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68b89269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metrics = pd.DataFrame(metrics)\n",
    "\n",
    "metrics.head()\n",
    "\n",
    "metrics.to_csv(\"coin_metricsVar.csv\", index=False)\n",
    "\n",
    "df = metrics.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fff7955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  asset                      time AdrActCnt          HashRate  \\\n",
      "0   btc 2013-01-01 00:00:00+00:00     38733   23.995203419462   \n",
      "1   btc 2013-01-02 00:00:00+00:00     40911  22.6621365628253   \n",
      "2   btc 2013-01-03 00:00:00+00:00     52539   23.995203419462   \n",
      "3   btc 2013-01-04 00:00:00+00:00     46781  22.6621365628253   \n",
      "4   btc 2013-01-05 00:00:00+00:00     53959  20.8847140873096   \n",
      "\n",
      "           PriceUSD            SplyCur TxTfrCnt      PriceUSD_t-1  \\\n",
      "0  13.3313714219755  10618089.91051183    73221              None   \n",
      "1  13.2806068129749  10621914.90951183    83763  13.3313714219755   \n",
      "2  13.3840811484512  10625964.90701183    89550  13.2806068129749   \n",
      "3  13.4517211496201  10629789.90351183    96831  13.3840811484512   \n",
      "4   13.459406766803  10633314.90101183    86261  13.4517211496201   \n",
      "\n",
      "  TxTfrCnt_t-1 AdrActCnt_t-1      HashRate_t-1        SplyCur_t-1  \\\n",
      "0         None          None              None               None   \n",
      "1        73221         38733   23.995203419462  10618089.91051183   \n",
      "2        83763         40911  22.6621365628253  10621914.90951183   \n",
      "3        89550         52539   23.995203419462  10625964.90701183   \n",
      "4        96831         46781  22.6621365628253  10629789.90351183   \n",
      "\n",
      "       PriceUSD_t-2 TxTfrCnt_t-2 AdrActCnt_t-2      HashRate_t-2  \\\n",
      "0              None         None          None              None   \n",
      "1              None         None          None              None   \n",
      "2  13.3313714219755        73221         38733   23.995203419462   \n",
      "3  13.2806068129749        83763         40911  22.6621365628253   \n",
      "4  13.3840811484512        89550         52539   23.995203419462   \n",
      "\n",
      "         SplyCur_t-2   PriceUSD_target  day_of_week  month  \n",
      "0               None  13.2806068129749            1      1  \n",
      "1               None  13.3840811484512            2      1  \n",
      "2  10618089.91051183  13.4517211496201            3      1  \n",
      "3  10621914.90951183   13.459406766803            4      1  \n",
      "4  10625964.90701183  13.5044965078901            5      1  \n"
     ]
    }
   ],
   "source": [
    "# Preparing for the data sets for training and testing\n",
    "\n",
    "# Ensure datetime and sort\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df.sort_values('time', inplace=True)\n",
    "\n",
    "# Create lag features (previous day's metrics)\n",
    "df['PriceUSD_t-1'] = df['PriceUSD'].shift(1)\n",
    "df['TxTfrCnt_t-1'] = df['TxTfrCnt'].shift(1)\n",
    "df['AdrActCnt_t-1'] = df['AdrActCnt'].shift(1)\n",
    "df['HashRate_t-1'] = df['HashRate'].shift(1)\n",
    "df['SplyCur_t-1'] = df['SplyCur'].shift(1)\n",
    "\n",
    "# Create lag features (2 days ago metrics)\n",
    "df['PriceUSD_t-2'] = df['PriceUSD'].shift(2)\n",
    "df['TxTfrCnt_t-2'] = df['TxTfrCnt'].shift(2)\n",
    "df['AdrActCnt_t-2'] = df['AdrActCnt'].shift(2)\n",
    "df['HashRate_t-2'] = df['HashRate'].shift(2)\n",
    "df['SplyCur_t-2'] = df['SplyCur'].shift(2)\n",
    "\n",
    "\n",
    "\n",
    "# Target: future price (e.g., 1-day ahead)\n",
    "df['PriceUSD_target'] = df['PriceUSD'].shift(-1)\n",
    "\n",
    "# # Target: future price (e.g., 2-day ahead)\n",
    "# df['PriceUSD_target'] = df['PriceUSD'].shift(-2)\n",
    "\n",
    "# # Target: future price (e.g., 3-day ahead)\n",
    "# df['PriceUSD_target'] = df['PriceUSD'].shift(-3)\n",
    "\n",
    "# Gives the rolling mean and standard deviation for the last 3 days\n",
    "# Rolling mean is the average value of the PriceUSD over the last 3 days\n",
    "# Rolling std is the standard deviation of the PriceUSD over the last 3 days\n",
    "# df['PriceUSD_roll_mean_3'] = df['PriceUSD'].rolling(window=3).mean()\n",
    "# df['PriceUSD_roll_std_3'] = df['PriceUSD'].rolling(window=3).std()\n",
    "\n",
    "df['day_of_week'] = df['time'].dt.dayofweek\n",
    "df['month'] = df['time'].dt.month\n",
    "\n",
    "print(df.head())\n",
    "\n",
    " # Drop rows with NaNs from shifting\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a79a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_lstm_dataset(X, y, time_steps=5):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(time_steps, len(X)):\n",
    "        Xs.append(X[i-time_steps:i])\n",
    "        ys.append(y[i])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a02a247",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHashRate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTxTfrCnt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdrActCnt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSplyCur\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPriceUSD_t-1\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPriceUSD_target\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create sequences\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "X = df[['HashRate', 'TxTfrCnt', 'AdrActCnt', 'SplyCur', 'PriceUSD_t-1']].values\n",
    "y = df['PriceUSD_target'].values\n",
    "\n",
    "# Create sequences\n",
    "time_steps = 5\n",
    "X_seq, y_seq = create_lstm_dataset(X, y, time_steps)\n",
    "\n",
    "# Split manually for LSTM\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b20f6e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:73\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 73\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_tensorflow_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Dropout\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:88\u001b[0m\n\u001b[0;32m     86\u001b[0m     sys\u001b[38;5;241m.\u001b[39msetdlopenflags(_default_dlopen_flags)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraceback\u001b[38;5;241m.\u001b[39mformat_exc()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     90\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     91\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee https://www.tensorflow.org/install/errors \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     92\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfor some common causes and solutions.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you need help, create an issue \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     94\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat https://github.com/tensorflow/tensorflow/issues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     95\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand include the entire stack trace above this error message.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 73, in <module>\n    from tensorflow.python._pywrap_tensorflow_internal import *\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.\n\n\nFailed to load the native TensorFlow runtime.\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))  # Output layer for regression\n",
    "\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9fc34eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 3. Model Training\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 4. Predictions\u001b[39;00m\n\u001b[0;32m     16\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 2. Model Selection\n",
    "# Using RandomForestRegressor (you can replace it with any other regressor)\n",
    "# model = RandomForestRegressor(n_estimators=100, max_depth=20, random_state=42)\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "# 3. Model Training\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# 5. Evaluation - Calculate MAE\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "print(f\"Training MAE: {train_mae:.2f}\")\n",
    "print(f\"Test MAE: {test_mae:.2f}\")\n",
    "\n",
    "# 6. Visualize Predictions vs Actual Prices\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test.index, y_test, label='Actual Price', color='blue')\n",
    "plt.plot(y_test.index, y_test_pred, label='Predicted Price', color='red')\n",
    "plt.title('Actual vs Predicted Price')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price USD')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70821011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'time': df.loc[y_test.index, 'time'],\n",
    "    'actual': y_test.values,\n",
    "    'predicted': y_test_pred\n",
    "})\n",
    "df_results.to_csv(\"predictions_simple.csv\", index=False)\n",
    "print(\"Predictions saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c528717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
