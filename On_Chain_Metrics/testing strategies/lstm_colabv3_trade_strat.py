# -*- coding: utf-8 -*-
"""LSTM_colabv2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V8adIFyUmOWPRPhYvOSnqyRLhuSwYgQx
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

!pip install coinmetrics-api-client

from coinmetrics.api_client import CoinMetricsClient

client = CoinMetricsClient()

print(client)

import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

# 'SplyCntCur' - this is for the supply count of the current coin
# 'CapMrktCurUSD' - this is for the market capitalization of the current coin
# 'PriceUSD' - this is for the price of the current coin
# 'TxTfrValAdjUSD' - this is for the adjusted transaction value in USD
# 'TxTfrValUSD' - this is for the transaction value in USD
# 'TxTfrCnt' - this is for the transaction count
# 'IssContNtv' - this is for the native issuance count
# 'IssContPctAnn' - this is for the annual percentage of the issuance count
#
# metrics = client.get_asset_metrics(assets='btc', metrics=['PriceUSD','HashRate','TxTfrCnt','AdrActCnt', 'SplyCur'], start_time="2013-01-01", end_time="2023-01-02", frequency='1d')
# metrics = client.get_asset_metrics(assets='btc', metrics=['PriceUSD','HashRate','TxTfrCnt','AdrActCnt', 'SplyCur'], start_time="2023-01-01", end_time="2024-01-02", frequency='1d')
metrics = client.get_asset_metrics(assets='btc', metrics=['PriceUSD','HashRate','TxTfrCnt','AdrActCnt', 'SplyCur'], start_time="2015-01-01", end_time="2024-01-02", frequency='1d')

# PriceUSD	Bitcoin market price in USD
# SplyCur	Current circulating supply (BTC in existence)
# HashRate	Network hash rate (security strength)
# Difficulty	Mining difficulty (how hard it is to mine a block)
# TxTfrCnt	Number of transactions per day
# TxTfrValUSD	Total daily value transferred (in USD)
# AdrActCnt	Number of active addresses (daily)
# AdrNewCnt	Number of new addresses created
# BlkCnt	Number of blocks mined per day
# BlkSizeMean	Average block size (in bytes)
# FeeMeanUSD	Average transaction fee (in USD)
# FeeTotUSD	Total transaction fees paid that day (USD)
# IssTotNtv	Total issuance (BTC minted per day)
# RevNtv	Miner revenue (BTC)
# RevUSD	Miner revenue (USD)
# SplyFuture	Amount of BTC not yet mined (future supply)
# TxCnt	Total number of transactions
# TxTfrCnt	Total number of value transfers (non-zero transactions)
# PriceBTC	Price in BTC (used for altcoins mostly)
# TxTfrValAdjNtv	Adjusted transaction volume (removes self-sends, spam)

# metrics = client.get_asset_metrics(
#     assets='btc',
#     metrics=[
#         'PriceUSD', 'HashRate', 'TxTfrCnt',
#         'AdrActCnt', 'BlkCnt',
#         'FeeMeanUSD', 'FeeTotUSD', 'IssTotNtv', 'RevNtv', 'RevUSD',
#         'SplyCur','TxCnt', 'TxTfrValAdjNtv'
#     ],
#     start_time="2015-01-01",
#     end_time="2024-01-02",
#     frequency='1d'
# )

metrics = pd.DataFrame(metrics)

metrics.head()

metrics.to_csv("LSTM_File_.csv", index=False)

df = metrics.copy()

df['time'] = pd.to_datetime(df['time'])
df.sort_values('time', inplace=True)

df['TxTfrCnt'] = pd.to_numeric(df['TxTfrCnt'], errors='coerce')
df['AdrActCnt'] = pd.to_numeric(df['AdrActCnt'], errors='coerce')
df['SplyCur'] = pd.to_numeric(df['SplyCur'], errors='coerce')
df['PriceUSD'] = pd.to_numeric(df['PriceUSD'], errors='coerce')

df['TxTfrCnt_per_address'] = df['TxTfrCnt'] / df['AdrActCnt']
df['SplyCur_per_address'] = df['SplyCur'] / df['AdrActCnt']

# Target: future price (e.g., 1-day ahead)
df['PriceUSD_target'] = df['PriceUSD'].shift(-1)
df['TxTfrCnt_per_address'] = df['TxTfrCnt'] / df['AdrActCnt']
df['SplyCur_per_address'] = df['SplyCur'] / df['AdrActCnt']

# df['PriceUSD_target'] = pd.to_numeric(df['PriceUSD_target'], errors='coerce')
# df['PriceUSD_log'] = np.log1p(df['PriceUSD_target'])

# Add technical indicators
# Moving averages
df['MA_7'] = df['PriceUSD_target'].rolling(window=7).mean()
df['MA_30'] = df['PriceUSD_target'].rolling(window=30).mean()
# Trend_Strength
df['MA_7_30_ratio'] = df['MA_7'] / df['MA_30']

# Volatility
# Added volatility in the last 30 days
df['Volatility_30'] = df['PriceUSD_target'].rolling(window=30).std()



 # Drop rows with NaNs from shifting
df.dropna(inplace=True)

# Base features
# X = df[['HashRate', 'TxTfrCnt', 'AdrActCnt', 'SplyCur', 'PriceUSD_target', 'MA_7', 'MA_30', 'MA_7_30_ratio', 'Volatility_30']].values
# Just onchain values finalized with all the onchain metrics
# X = df[['HashRate', 'TxTfrCnt', 'AdrActCnt', 'SplyCur', 'PriceUSD']].values
# All the onchain metrics
# X = df[['PriceUSD', 'HashRate', 'TxTfrCnt',
#         'AdrActCnt', 'BlkCnt',
#         'FeeMeanUSD', 'FeeTotUSD', 'IssTotNtv', 'RevNtv', 'RevUSD',
#         'SplyCur','TxCnt', 'TxTfrValAdjNtv']]
# Just the price usd
X = df[['PriceUSD']]
# Base onchain metrics usage
# X = df[['PriceUSD','HashRate','TxTfrCnt','AdrActCnt', 'SplyCur']].values

# X = df[['HashRate']].values
y = df['PriceUSD_target'].values
# y = df['PriceUSD'].values

# from sklearn.preprocessing import MinMaxScaler

# # Scale the features and target
# scaler_X = MinMaxScaler()
# scaler_y = MinMaxScaler()

# X_scaled = scaler_X.fit_transform(X)
# y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))

from sklearn.preprocessing import MinMaxScaler

# Scale the features and target
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y.reshape(-1, 1))

import joblib

joblib.dump(scaler_X, "btc_scaler_X_PriceUSD_v2.pkl")
joblib.dump(scaler_y, "btc_scaler_y_PriceUSD_v2.pkl")


def create_sequences(X, y, time_steps=60):
    X_seq, y_seq = [], []
    for i in range(len(X) - time_steps):
        X_seq.append(X[i:i + time_steps])
        y_seq.append(y[i + time_steps])
    return np.array(X_seq), np.array(y_seq)

# Choose an appropriate sequence length (e.g., 60 days)
time_steps = 60
X_seq, y_seq = create_sequences(X_scaled, y_scaled, time_steps)

# Reshape the input to be 3D [samples, time steps, features]
from sklearn.model_selection import train_test_split

# Split into train (70%), validation (15%), and test (15%)
X_train, X_temp, y_train, y_temp = train_test_split(X_seq, y_seq, test_size=0.3, shuffle=False)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)
n_features = X_train.shape[2]

# Building the LSTM model

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Conv1D, MaxPooling1D, Bidirectional
from tensorflow.keras.layers import Flatten, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l1_l2
import tensorflow as tf

from tensorflow.keras.optimizers import Adam


# CNN Model
# model = Sequential()
# # First convolutional layer
# model.add(Conv1D(filters=64, kernel_size=3, activation='relu',
#                  input_shape=(time_steps, n_features)))
# model.add(MaxPooling1D(pool_size=2))

# # Second convolutional layer
# model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))
# model.add(MaxPooling1D(pool_size=2))

# # LSTM layers follow after the CNN feature extractors
# model.add(LSTM(units=50, return_sequences=True))
# model.add(Dropout(0.4))
# model.add(LSTM(units=50))
# model.add(Dropout(0.2))

# # Final dense layer for output
# model.add(Dense(1))

# # BIDIRECTIONAL LSTM Model Base
# model = Sequential()
# model.add(Bidirectional(LSTM(units=50, return_sequences=True),
#                         input_shape=(time_steps, n_features)))
# # changed dropout from 0.4 to 0.3
# model.add(Dropout(0.4))
# # changing to 100 units of neurons
# model.add(Bidirectional(LSTM(units=100)))
# # changed dropout from 0.2 to 0.3
# # changed dropout from 0.3 to 0.4
# model.add(Dropout(0.4))
# # model.add(Dense(256))  # First dense layer with 256 neurons
# model.add(Dense(1))
# model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')

# BIDIRECTIONAL LSTM Model Base Modifications

model = Sequential()
# Change the number of neurosn from 100 to 356
model.add(Bidirectional(LSTM(units=356, return_sequences=True, activation = tf.tanh),
                        input_shape=(time_steps, n_features)))
# Added BatchNormalization
# model.add(BatchNormalization())
# changed dropout from 0.4 to 0.3
model.add(Dropout(0.1))
# changing to 100 units of neurons
model.add(Bidirectional(LSTM(units=356,return_sequences=True, activation=tf.tanh)))
# changed dropout from 0.2 to 0.3
# changed dropout from 0.3 to 0.4
model.add(Dropout(0.1))
# 3rd (and final) Bi‑LSTM: returns only the last output vector
model.add(Bidirectional(
    LSTM(units=356, return_sequences=False)
))
model.add(Dropout(0.1))
model.add(Dense(1))
model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')

# Improved Bidirectional Model with Regularization and Batch Normalization
# from tensorflow.keras.optimizers import Adam
# from tensorflow.keras.callbacks import EarlyStopping

# # Minimal modification to your base model
# model = Sequential()
# # Layer 1, Bidirectional LSTM with Batch Normalization
# model.add(Bidirectional(LSTM(units=50, return_sequences=True),
#                         input_shape=(time_steps, n_features)))
# # model.add(BatchNormalization())  # Added Batch Normalization
# model.add(Dropout(0.3))  # Slightly reduced dropout
# # Layer 2, Bidirectional LSTM w
# model.add(Bidirectional(LSTM(units=128, return_sequences=True)))
# # model.add(BatchNormalization())  # Added Batch Normalization
# model.add(Dropout(0.4))
# # Layer 3, Bidirectional layer with Batch Normalization
# model.add(Bidirectional(LSTM(units=40)))
# # model.add(BatchNormalization())  # Added Batch Normalization
# model.add(Dropout(0.3))

# # Layer 4, Dense layer with Batch Normalization
# model.add(Dense(units=100, activation='relu'))
# # model.add(BatchNormalization())
# model.add(Dropout(0.2))

# # Dense Layer for output
# model.add(Dense(1, activation='linear'))  # Linear activation for regression

# # Only changed learning rate
# optimizer = Adam(learning_rate=0.001)
# model.compile(optimizer=optimizer, loss='mean_squared_error')

# Add just early stopping
# early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# # Train with early stopping
# history = model.fit(
#     X_train, y_train,
#     epochs=100,
#     batch_size=32,  # Adjust if needed
#     validation_split=0.2,
#     callbacks=[early_stop]
# )

# # Bidirectional LSTM Model with Regularization with Recurrent Dropout
# from tensorflow.keras.regularizers import l2
# n_features = X_train.shape[2]
# model = Sequential()
# model.add(Bidirectional(
#     LSTM(50, return_sequences=True,
#          recurrent_dropout=0.1,
#          kernel_regularizer=l2(1e-4),
#          recurrent_regularizer=l2(1e-4)),
#     input_shape=(time_steps, n_features)))
# model.add(Dropout(0.3))

# model.add(Bidirectional(
#     LSTM(50,
#          recurrent_dropout=0.1,
#          kernel_regularizer=l2(1e-4),
#          recurrent_regularizer=l2(1e-4))))
# model.add(Dropout(0.2))

# model.add(Dense(32, activation='relu', kernel_regularizer=l2(1e-4)))
# model.add(Dense(1))
# model.compile(optimizer=Adam(learning_rate=1e-4), loss='mean_squared_error')

# # Simple attention layer
# from tensorflow.keras.layers import Layer, Permute, Multiply, Lambda, Activation, Dense, Flatten, RepeatVector
# import tensorflow.keras.backend as K

# class Attention(Layer):
#     def build(self, input_shape):
#         self.W = self.add_weight(shape=(input_shape[-1], 1),
#                                  initializer='glorot_uniform',
#                                  trainable=True)
#         super().build(input_shape)

#     def call(self, x):
#         # x shape: (batch, timesteps, features)
#         e = K.squeeze(K.dot(x, self.W), axis=-1)           # (batch, timesteps)
#         α = K.softmax(e)                                   # attention weights
#         α = K.expand_dims(α, axis=-1)                      # (batch, timesteps, 1)
#         return K.sum(x * α, axis=1)                        # (batch, features)

# # Build with attention
# model = Sequential()
# model.add(Bidirectional(LSTM(50, return_sequences=True), input_shape=(time_steps, n_features)))
# model.add(Dropout(0.3))
# model.add(Bidirectional(LSTM(50, return_sequences=True)))
# model.add(Dropout(0.2))
# model.add(Attention())
# model.add(Dense(32, activation='relu'))
# model.add(Dense(1))
# model.compile(Adam(1e-4), 'mean_squared_error')


# # LSTM Model BASE
# # Get input dimensions
# # Build model
# model = Sequential()
# model.add(LSTM(units=50, return_sequences=True, input_shape=(time_steps, n_features)))
# # units = 50 is a common choice for LSTM layers, but you can experiment with this value adds 50 memory cells (neurons)
# model.add(Dropout(0.2))
# # Dropout layer to prevent overfitting, drops 20% of the neurons
# # Add another LSTM layer but returns only the last output

# model.add(LSTM(units=50))
# model.add(Dropout(0.2))
# # -----
# model.add(Dense(units=1))
# # Predicting a single value (the next price)

# # Compile model with a slightly lower learning rate for stability
# model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')

# Train the model with a validation split
from tensorflow.keras.callbacks import EarlyStopping

# Add early stopping to prevent overfitting
early_stop = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)

# Train the model
history = model.fit(
    X_train, y_train,
    epochs=600,
    # Epoch increased from 200 to 600
    # Increased Batch_size from 32 to 64
    batch_size=64,
    validation_data=(X_val, y_val),
    callbacks=[early_stop],
    verbose=1
)

import numpy
numpy.version.version

import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
model.save('Bit_Coin_Price_Prediction_LSTM_Model_PriceUSD_Ver2.keras')
model.save_weights('Bit_Coin_Price_Prediction_LSTM_Model_PriceUSD_Weights.weights.h5')

# plt.plot(history.history['loss'],   label='train')
# plt.plot(history.history['val_loss'], label='validation')
# plt.title("Training vs. Validation Loss")
# plt.xlabel("Epoch")
# plt.ylabel("Loss")
# plt.legend()
# plt.show()

plt.plot(history.history['loss'],   label='Train Loss')
plt.plot(history.history['val_loss'], label='Val   Loss')
plt.xlabel('Epoch')
plt.ylabel('MSE Loss')
plt.legend()
plt.show()

# Evaluation and make predictions
# Predict on test data
y_pred_scaled = model.predict(X_test)

# Inverse transform to get actual price values
y_pred = scaler_y.inverse_transform(y_pred_scaled)
y_test_actual = scaler_y.inverse_transform(y_test)

# Calculate metrics
from sklearn.metrics import mean_squared_error, mean_absolute_error
import math

rmse = math.sqrt(mean_squared_error(y_test_actual, y_pred))
mae = mean_absolute_error(y_test_actual, y_pred)
print(f"RMSE for testing: {rmse}")
print(f"MAE for testing: {mae}")

def directional_accuracy(y_true, y_pred):
    y_true_direction = np.sign(np.diff(y_true.flatten()))
    y_pred_direction = np.sign(np.diff(y_pred.flatten()))
    return np.mean(y_true_direction == y_pred_direction)

dir_acc = directional_accuracy(y_test_actual, y_pred)

print(f"RMSE for testing: {rmse}")
print(f"MAE for testing: {mae}")
print(f"Directional Accuracy: {dir_acc:.4f}")

# # Visualizing the result
# import matplotlib.pyplot as plt

# # Visualize predictions
# plt.figure(figsize=(14, 7))
# plt.plot(y_test_actual, label='Actual Price', color='blue')
# plt.plot(y_pred, label='Predicted Price', color='red', linestyle='--')
# plt.title('Bitcoin Price Prediction')
# plt.xlabel('Time')
# plt.ylabel('Price USD')
# plt.legend()
# plt.grid(True)
# plt.show()

# After your predictions and metrics calculations:

# Get the dates for the test set
# We need to find the dates that correspond to our test set
test_dates = df['time'].iloc[-(len(y_test_actual)):]

# Visualizing the result with dates
plt.figure(figsize=(14, 7))
plt.plot(test_dates, y_test_actual, label='Actual Price', linewidth=2)
plt.plot(test_dates, y_pred, label='Predicted Price', linewidth=2, alpha=0.8)
plt.title(f'Bitcoin Price Prediction (RMSE: {rmse:.2f}, MAE: {mae:.2f})')
plt.xlabel('Date')
plt.ylabel('Price USD')
plt.legend()
plt.grid(alpha=0.3)

# Format x-axis to show dates properly
plt.gcf().autofmt_xdate()
plt.tight_layout()

# Add text annotation for metrics
plt.figtext(0.15, 0.02, f"RMSE: {rmse:.2f} | MAE: {mae:.2f} | Dir. Accuracy: {dir_acc:.4f}",
            ha="left", fontsize=12, bbox={"facecolor":"white", "alpha":0.5, "pad":5})

plt.show()

# # import numpy as np
# # import matplotlib.pyplot as plt
# # from tensorflow.keras.models import load_model
# # # Load your real models and scalers instead of dummies
# # import joblib

# # # Define the agent class
# # class LSTMTradingAgent:
# #     def __init__(self, name, model, scaler_X, scaler_y, initial_cash=10000):
# #         self.name = name
# #         self.model = model
# #         self.scaler_X = scaler_X
# #         self.scaler_y = scaler_y
# #         self.cash = initial_cash
# #         self.crypto = 0
# #         self.history = []

# #     def act(self, X_current_scaled, price_now):
# #         """Decide action using LSTM model"""
# #         y_pred_prob = self.model.predict(X_current_scaled.reshape(1, *X_current_scaled.shape), verbose=0)
# #         action = np.argmax(y_pred_prob, axis=1)[0]  # 0=BUY, 1=SELL, 2=HOLD

# #         if action == 0 and self.cash > 0:  # BUY
# #             self.crypto = self.cash / price_now
# #             self.cash = 0
# #         elif action == 1 and self.crypto > 0:  # SELL
# #             self.cash = self.crypto * price_now
# #             self.crypto = 0
# #         # HOLD: do nothing

# #         total_balance = self.cash + self.crypto * price_now
# #         self.history.append(total_balance)

# #     def get_final_balance(self, price_now):
# #         return self.cash + self.crypto * price_now

# # # Dummy scalers (replace with your real scalers)
# # class DummyScaler:
# #     def transform(self, X):
# #         return X  # Assume already scaled for dummy
# #     def inverse_transform(self, X):
# #         return X

# # # Dummy model (replace with your trained model)
# # class DummyModel:
# #     def predict(self, X, verbose=0):
# #         batch_size = X.shape[0]
# #         return np.tile([1/3, 1/3, 1/3], (batch_size, 1))  # Equal probability



# # # Load your real trained LSTM model
# # model1 = load_model("OnChainAnalysis/AgentSimulation/Agent_Config_Files/Bit_Coin_Price_Prediction_LSTM_Model_Base_.keras")  # <-- your path
# # scaler_X1 = joblib.load("OnChainAnalysis/AgentSimulation/Agent_Config_Files/btc_scaler_X_4ChainMetrics.pkl")
# # scaler_y1 = joblib.load("OnChainAnalysis/AgentSimulation/Agent_Config_Files/btc_scaler_y_4ChainMetrics.pkl")

# # # (Optional) Load a second different model for Agent 2
# # model2 = load_model("OnChainAnalysis\AgentSimulation\Agent_Config_Files\Bit_Coin_Price_Prediction_LSTM_Model_PriceUSD_Ver2.keras")  # if you have an ETH model
# # scaler_X2 = joblib.load("OnChainAnalysis\AgentSimulation\Agent_Config_Files\btc_scaler_X_priceUSD.pkl")
# # scaler_y2 = joblib.load("OnChainAnalysis\AgentSimulation\Agent_Config_Files\btc_scaler_y_4ChainMetrics.pkl")

# # # Simulate price and features (replace with real data)
# # np.random.seed(42)
# # prices = np.cumsum(np.random.randn(1000)) + 30000  # Fake BTC price simulation
# # X_features = np.random.randn(1000, 60, 10)  # Dummy 60 days x 10 features

# # # Initialize agents
# # agent = LSTMTradingAgent(
# #     name="BTC_LSTM_Agent",
# #     model=model,
# #     scaler_X=scaler_X1,
# #     scaler_y=scaler_y1,
# #     initial_cash=10000  # starting cash
# # )

# # # Simulation loop
# # print("Starting simulation...")
# # time_steps = 60
# # for t in range(time_steps, len(prices)):
# #     X_window = X_features[t - time_steps:t]  # last 60 days window
# #     price_now = prices[t]

# #     for agent in agents:
# #         agent.act(X_window, price_now)

# # # Evaluation
# # print("\nFinal Results:")
# # for agent in agents:
# #     final_balance = agent.get_final_balance(prices[-1])
# #     print(f"{agent.name} Final Balance: ${final_balance:.2f}")

# # # Plot results
# # plt.figure(figsize=(14,7))
# # for agent in agents:
# #     plt.plot(agent.history, label=agent.name)

# # plt.title("Agent Wealth Over Time")
# # plt.xlabel("Days")
# # plt.ylabel("Portfolio Value (USD)")
# # plt.legend()
# # plt.grid(True)
# # plt.tight_layout()
# # plt.show()
# import numpy as np
# import matplotlib.pyplot as plt
# from tensorflow.keras.models import load_model
# import joblib

# # Define the agent class
# class LSTMTradingAgent:
#     def __init__(self, name, model, scaler_X, scaler_y, initial_cash=10000):
#         self.name = name
#         self.model = model
#         self.scaler_X = scaler_X
#         self.scaler_y = scaler_y
#         self.cash = initial_cash
#         self.crypto = 0
#         self.history = []

#     def act(self, X_current_scaled, price_now):
#         y_pred_prob = self.model.predict(X_current_scaled.reshape(1, *X_current_scaled.shape), verbose=0)
#         action = np.argmax(y_pred_prob, axis=1)[0]  # 0=BUY, 1=SELL, 2=HOLD

#         if action == 0 and self.cash > 0:  # BUY
#             self.crypto = self.cash / price_now
#             self.cash = 0
#         elif action == 1 and self.crypto > 0:  # SELL
#             self.cash = self.crypto * price_now
#             self.crypto = 0
#         # HOLD: do nothing

#         total_balance = self.cash + self.crypto * price_now
#         self.history.append(total_balance)

#     def get_final_balance(self, price_now):
#         return self.cash + self.crypto * price_now

# # Load your real trained LSTM model and scalers
# model1 = load_model("OnChainAnalysis/AgentSimulation/Agent_Config_Files/Bit_Coin_Price_Prediction_LSTM_Model_Base_.keras", )
# scaler_X1 = joblib.load("OnChainAnalysis/AgentSimulation/Agent_Config_Files/btc_scaler_X_4ChainMetrics.pkl")
# scaler_y1 = joblib.load("OnChainAnalysis/AgentSimulation/Agent_Config_Files/btc_scaler_y_4ChainMetrics.pkl")

# # Simulate price and features (replace with real data later)
# np.random.seed(42)
# prices = np.cumsum(np.random.randn(1000)) + 30000  # Dummy BTC prices
# X_features = np.random.randn(1000, 60, 10)  # Dummy features

# # Initialize a list of agents (just one for now)
# agents = [
#     LSTMTradingAgent(
#         name="BTC_LSTM_Agent",
#         model=model1,
#         scaler_X=scaler_X1,
#         scaler_y=scaler_y1,
#         initial_cash=10000
#     )
# ]

# # Simulation loop
# print("Starting simulation...")
# time_steps = 60
# for t in range(time_steps, len(prices)):
#     X_window = X_features[t - time_steps:t]  # Last 60 days window
#     price_now = prices[t]

#     for agent in agents:
#         agent.act(X_window, price_now)

# # Evaluation
# print("\nFinal Results:")
# for agent in agents:
#     final_balance = agent.get_final_balance(prices[-1])
#     print(f"{agent.name} Final Balance: ${final_balance:.2f}")

# # Plot results
# plt.figure(figsize=(14,7))
# for agent in agents:
#     plt.plot(agent.history, label=agent.name)

# plt.title("Agent Wealth Over Time")
# plt.xlabel("Days")
# plt.ylabel("Portfolio Value (USD)")
# plt.legend()
# plt.grid(True)
# plt.tight_layout()
# plt.show()
# # This code simulates a trading agent using an LSTM model to predict Bitcoin prices and make buy/sell decisions based on the predictions. The agent's performance is evaluated by tracking its portfolio value over time.
# # The simulation uses dummy data for prices and features, which should be replaced with real data in a production environment.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
import joblib

# --- Load real feature data ---
df = pd.read_csv("/content/LSTM_File_4ChainMetrics.csv")
df['time'] = pd.to_datetime(df['time'])
df = df.sort_values('time')

# ✨ Filter the data
start_date = '2021-01-01'
end_date = '2021-12-31'
df = df[(df['time'] >= start_date) & (df['time'] <= end_date)]

features = df[['PriceUSD', 'HashRate', 'TxTfrCnt', 'AdrActCnt', 'SplyCur']].values
prices = df['PriceUSD'].values

# --- Define the Agent class ---
class LSTMTradingAgent:
    def __init__(self, name, model, scaler_X, scaler_y, initial_cash=100):
        self.name = name
        self.model = model
        self.scaler_X = scaler_X
        self.scaler_y = scaler_y
        self.initial_cash = initial_cash
        self.cash = initial_cash
        self.crypto = 0
        self.history = []

    def predict_price(self, X_window):
        X_scaled = self.scaler_X.transform(X_window)
        X_scaled = X_scaled.reshape(1, *X_scaled.shape)
        y_pred_scaled = self.model.predict(X_scaled, verbose=0)
        predicted_price = self.scaler_y.inverse_transform(y_pred_scaled)[0, 0]
        return predicted_price

    def act(self, X_window, price_now):
        raise NotImplementedError("Subclasses should implement this!")

    def get_final_balance(self, price_now):
        return self.cash + self.crypto * price_now


class GreedyBuyer(LSTMTradingAgent):
    def act(self, X_window, price_now):
        predicted_price = self.predict_price(X_window)

        if predicted_price > price_now * 1.001 and self.cash > 0:
            self.crypto += self.cash / price_now
            self.cash = 0
        elif predicted_price < price_now * 0.999 and self.crypto > 0:
            self.cash += self.crypto * price_now
            self.crypto = 0

        self.history.append(self.get_final_balance(price_now))

class CautiousHolder(LSTMTradingAgent):
    def act(self, X_window, price_now):
        predicted_price = self.predict_price(X_window)

        if predicted_price > price_now * 1.05 and self.cash > 0:
            # Only use 25% of cash
            amount = 0.25 * self.cash
            self.crypto += amount / price_now
            self.cash -= amount
        elif predicted_price < price_now * 0.98 and self.crypto > 0:
            # Only sell 50% of crypto
            amount = 0.5 * self.crypto
            self.cash += amount * price_now
            self.crypto -= amount

        self.history.append(self.get_final_balance(price_now))

class PartialTrader(LSTMTradingAgent):
    def act(self, X_window, price_now):
        predicted_price = self.predict_price(X_window)

        if predicted_price > price_now * 1.01 and self.cash > 0:
            amount = 0.10 * self.cash
            self.crypto += amount / price_now
            self.cash -= amount
        elif predicted_price < price_now * 0.99 and self.crypto > 0:
            amount = 0.10 * self.crypto
            self.cash += amount * price_now
            self.crypto -= amount

        self.history.append(self.get_final_balance(price_now))



# --- Load trained LSTM model and scalers ---
# model = load_model('/content/Bit_Coin_Price_Prediction_LSTM_Model_4ChainMetrics_Ver2.h5')
model = load_model('/content/Bit_Coin_Price_Prediction_LSTM_Model_PriceUSD_Ver2.h5')
scaler_X = joblib.load('/content/btc_scaler_X_4ChainMetrics.pkl')
scaler_y = joblib.load('/content/btc_scaler_y_4ChainMetrics.pkl')

# --- Initialize agents ---
# agents = [
#     LSTMTradingAgent(name="BTC_LSTM_Agent", model=model, scaler_X=scaler_X, scaler_y=scaler_y)
# ]

agents = [
    GreedyBuyer(name="GreedyBuyer", model=model, scaler_X=scaler_X, scaler_y=scaler_y),
    CautiousHolder(name="CautiousHolder", model=model, scaler_X=scaler_X, scaler_y=scaler_y),
    PartialTrader(name="PartialTrader", model=model, scaler_X=scaler_X, scaler_y=scaler_y)
]


# --- Simulation Loop ---
time_steps = 60
print("Starting tournament simulation...")
for t in range(time_steps, len(prices)):
    X_window = features[t - time_steps:t]
    price_now = prices[t]

    for agent in agents:
        agent.act(X_window, price_now)
        # Optional: print only every 100 steps
        if t % 100 == 0:
          print(f"Day {t}: BTC Price = {price_now:.2f}")

# --- Results ---
print("\nFinal Tournament Results:")
for agent in agents:
    final_balance = agent.get_final_balance(prices[-1])
    growth = (final_balance - agent.initial_cash) / agent.initial_cash * 100
    print(f"{agent.name} Final Balance: ${final_balance:.2f} ({growth:.2f}% growth)")


# --- Plotting ---
plt.figure(figsize=(14, 7))
for agent in agents:
    plt.plot(agent.history, label=agent.name)

# plt.figure(figsize=(14,7))
# plt.plot(df['time'].iloc[time_steps:], prices[time_steps:], label='BTC Price', color='blue')
# plt.plot(df['time'].iloc[time_steps:], agents[0].history, label=agents[0].name, color='green')
# plt.title('BTC Price vs Agent Portfolio Over Time')
# plt.xlabel('Date')
# plt.ylabel('USD Value')
# plt.legend()
# plt.grid(True)
# plt.show()

plt.figure(figsize=(14, 7))
for agent in agents:
    plt.plot(agent.history, label=agent.name)

plt.title('Agent Portfolio Over Time')
plt.xlabel('Days')
plt.ylabel('Portfolio Value (USD)')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
import joblib
import os
from datetime import datetime
from sklearn.preprocessing import MinMaxScaler
import logging

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler("trading_sim.log"), logging.StreamHandler()]
)
logger = logging.getLogger("trading_simulation")

class BaseTradingAgent:
    """Base class for all trading agents with common functionality"""

    def __init__(self, name, initial_cash=100):
        self.name = name
        self.initial_cash = initial_cash
        self.cash = initial_cash
        self.crypto = 0
        self.history = []
        self.actions = []  # Track buy/sell/hold actions
        self.transaction_prices = []  # Track prices at transaction times

    def get_final_balance(self, price_now):
        """Calculate final portfolio value"""
        return self.cash + self.crypto * price_now

    def get_performance_metrics(self, prices):
        """Calculate various performance metrics"""
        returns = np.diff(self.history) / self.history[:-1]

        metrics = {
            'final_balance': self.history[-1],
            'growth_pct': (self.history[-1] - self.initial_cash) / self.initial_cash * 100,
            'max_drawdown_pct': self._calculate_max_drawdown(self.history) * 100,
            'sharpe_ratio': np.mean(returns) / np.std(returns) if len(returns) > 0 and np.std(returns) > 0 else 0,
            'volatility': np.std(returns) * 100 if len(returns) > 0 else 0,
            'buy_and_hold_return': (prices[-1] - prices[0]) / prices[0] * 100,
            'num_trades': len([a for a in self.actions if a != 'HOLD'])
        }

        return metrics

    def _calculate_max_drawdown(self, portfolio_values):
        """Calculate maximum drawdown from peak to trough"""
        max_so_far = portfolio_values[0]
        max_drawdown = 0

        for value in portfolio_values:
            if value > max_so_far:
                max_so_far = value
            drawdown = (max_so_far - value) / max_so_far
            max_drawdown = max(max_drawdown, drawdown)

        return max_drawdown

class MomentumTrader(LSTMTradingAgent):
    """Agent that trades based on price momentum and volume trends"""

    def act(self, X_window, price_now):
        # Calculate short and long moving averages (5-day and 20-day)
        short_ma = np.mean(X_window[-5:, 0])  # 5-day price MA
        long_ma = np.mean(X_window[-20:, 0])  # 20-day price MA

        # Calculate momentum and volume trend
        momentum = short_ma / long_ma - 1

        # Volume index (assuming it's in the data - adjust column index as needed)
        volume_trend = np.mean(X_window[-5:, 2]) / np.mean(X_window[-20:, 2]) - 1

        action = "HOLD"

        # Strong buy signal: positive momentum, increasing volume, model agrees
        if momentum > 0.02 and volume_trend > 0 and self.cash > 0:
            amount = min(self.cash, self.cash * (momentum * 10))  # Size based on momentum
            self.crypto += amount / price_now * 0.99  # Account for 1% fee
            self.cash -= amount
            action = "BUY"

        # Strong sell signal: negative momentum, increasing volume
        elif momentum < -0.02 and volume_trend > 0 and self.crypto > 0:
            amount = self.crypto * min(1.0, abs(momentum * 10))  # Size based on momentum
            self.cash += amount * price_now * 0.99  # Account for 1% fee
            self.crypto -= amount
            action = "SELL"

        self.actions.append(action)
        self.history.append(self.get_final_balance(price_now))


class LSTMTradingAgent(BaseTradingAgent):
    """Trading agent using LSTM model for price predictions"""

    def __init__(self, name, model, scaler_X, scaler_y, initial_cash=100):
        super().__init__(name, initial_cash)
        self.model = model
        self.scaler_X = scaler_X
        self.scaler_y = scaler_y

    def predict_price(self, X_window):
        """Make price prediction using the LSTM model"""
        try:
            X_scaled = self.scaler_X.transform(X_window)
            X_scaled = X_scaled.reshape(1, *X_scaled.shape)
            y_pred_scaled = self.model.predict(X_scaled, verbose=0)
            predicted_price = self.scaler_y.inverse_transform(y_pred_scaled)[0, 0]
            return predicted_price
        except Exception as e:
            logger.error(f"Error in price prediction: {e}")
            # Return current price as fallback (last value in X_window)
            return X_window[-1, 0]  # Assuming price is the first feature

    def act(self, X_window, price_now):
        """Base implementation - should be overridden by subclasses"""
        raise NotImplementedError("Subclasses should implement this!")


class GreedyBuyer(LSTMTradingAgent):
    """Agent that buys/sells aggressively based on predicted price direction"""

    def act(self, X_window, price_now):
        predicted_price = self.predict_price(X_window)
        action = "HOLD"

        # Buy if predicted price is higher by threshold
        if predicted_price > price_now * 1.001 and self.cash > 0:
            self.crypto += self.cash / price_now * 0.99  # Account for 1% transaction fee
            self.cash = 0
            action = "BUY"
            self.transaction_prices.append(price_now)

        # Sell if predicted price is lower by threshold
        elif predicted_price < price_now * 0.999 and self.crypto > 0:
            self.cash += self.crypto * price_now * 0.99  # Account for 1% transaction fee
            self.crypto = 0
            action = "SELL"
            self.transaction_prices.append(price_now)

        self.actions.append(action)
        self.history.append(self.get_final_balance(price_now))


class CautiousHolder(LSTMTradingAgent):
    """Agent that trades partially and requires stronger signals"""

    def act(self, X_window, price_now):
        predicted_price = self.predict_price(X_window)
        action = "HOLD"

        # Look at the trend over the past window
        price_trend = X_window[-5:, 0]  # Last 5 days of prices
        trend_direction = 1 if np.mean(np.diff(price_trend)) > 0 else -1

        # Buy if strong positive signal and confirming trend
        if predicted_price > price_now * 1.05 and trend_direction > 0 and self.cash > 0:
            amount = 0.25 * self.cash
            self.crypto += amount / price_now * 0.99  # Account for 1% fee
            self.cash -= amount
            action = "BUY"
            self.transaction_prices.append(price_now)

        # Sell if strong negative signal and confirming trend
        elif predicted_price < price_now * 0.98 and trend_direction < 0 and self.crypto > 0:
            amount = 0.5 * self.crypto
            self.cash += amount * price_now * 0.99  # Account for 1% fee
            self.crypto -= amount
            action = "SELL"
            self.transaction_prices.append(price_now)

        self.actions.append(action)
        self.history.append(self.get_final_balance(price_now))


class VolumeWeightedTrader(LSTMTradingAgent):
    """Agent that adjusts position sizes based on prediction confidence"""

    def __init__(self, name, model, scaler_X, scaler_y, initial_cash=100, confidence_thresholds=[0.01, 0.03, 0.05]):
        super().__init__(name, model, scaler_X, scaler_y, initial_cash)
        self.confidence_thresholds = confidence_thresholds

    def act(self, X_window, price_now, volume_now=None):
        predicted_price = self.predict_price(X_window)
        percent_change = (predicted_price - price_now) / price_now
        action = "HOLD"

        # Determine position size based on confidence level
        position_size = 0
        for i, threshold in enumerate(self.confidence_thresholds):
            if abs(percent_change) > threshold:
                position_size = (i + 1) / len(self.confidence_thresholds)

        # Execute trade with dynamic position sizing
        if percent_change > 0.01 and self.cash > 0:  # Buy signal
            trade_amount = self.cash * position_size
            if trade_amount > 0:
                self.crypto += trade_amount / price_now * 0.99  # Account for 1% fee
                self.cash -= trade_amount
                action = f"BUY ({int(position_size*100)}%)"
                self.transaction_prices.append(price_now)

        elif percent_change < -0.01 and self.crypto > 0:  # Sell signal
            crypto_amount = self.crypto * position_size
            if crypto_amount > 0:
                self.cash += crypto_amount * price_now * 0.99  # Account for 1% fee
                self.crypto -= crypto_amount
                action = f"SELL ({int(position_size*100)}%)"
                self.transaction_prices.append(price_now)

        self.actions.append(action)
        self.history.append(self.get_final_balance(price_now))


def load_data(file_path, start_date=None, end_date=None):
    """Load and preprocess data from CSV file"""
    try:
        logger.info(f"Loading data from {file_path}")
        df = pd.read_csv(file_path)

        # Handle date conversion
        df['time'] = pd.to_datetime(df['time'])
        df = df.sort_values('time')

        # Filter by date range if provided
        if start_date and end_date:
            df = df[(df['time'] >= start_date) & (df['time'] <= end_date)]

        # Handle missing values
        df = df.fillna(method='ffill').fillna(method='bfill')

        logger.info(f"Loaded {len(df)} rows of data from {df['time'].min()} to {df['time'].max()}")
        return df
    except Exception as e:
        logger.error(f"Error loading data: {e}")
        raise


def load_models(model_path, scaler_X_path, scaler_y_path):
    """Load trained model and scalers"""
    try:
        logger.info(f"Loading model from {model_path}")
        model = load_model(model_path)
        scaler_X = joblib.load(scaler_X_path)
        scaler_y = joblib.load(scaler_y_path)
        return model, scaler_X, scaler_y
    except Exception as e:
        logger.error(f"Error loading models: {e}")
        raise


def run_simulation(df, features_cols, price_col, agents, time_steps=60, transaction_fee_pct=0.01):
    """Run the trading simulation"""
    features = df[features_cols].values
    prices = df[price_col].values
    dates = df['time'].values

    logger.info(f"Starting simulation with {len(agents)} agents over {len(prices)-time_steps} time steps")

    # Create a benchmark buy-and-hold agent
    buy_and_hold = BaseTradingAgent("Buy_and_Hold", initial_cash=100)
    buy_and_hold.crypto = buy_and_hold.cash / prices[time_steps] * (1-transaction_fee_pct)
    buy_and_hold.cash = 0

    # Simulation loop
    for t in range(time_steps, len(prices)):
        X_window = features[t - time_steps:t]
        price_now = prices[t]

        # Update agents
        for agent in agents:
            agent.act(X_window, price_now)

        # Update buy-and-hold benchmark
        buy_and_hold.history.append(buy_and_hold.get_final_balance(price_now))

        # Log progress periodically
        if t % 50 == 0 or t == len(prices)-1:
            logger.info(f"Day {t-time_steps}/{len(prices)-time_steps}: Price = ${price_now:.2f}")

    # Add buy-and-hold to agents for performance comparison
    agents.append(buy_and_hold)

    return agents, prices, dates


def evaluate_performance(agents, prices, save_dir="results"):
    """Evaluate and display agent performance"""
    os.makedirs(save_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # Calculate metrics for all agents
    results = []
    for agent in agents:
        metrics = agent.get_performance_metrics(prices)
        metrics['agent_name'] = agent.name
        results.append(metrics)

        # Log results
        logger.info(f"\n--- {agent.name} Performance ---")
        for metric, value in metrics.items():
            if metric != 'agent_name':
                logger.info(f"{metric}: {value:.2f}")

    # Save results to CSV
    results_df = pd.DataFrame(results)
    results_df.to_csv(f"{save_dir}/agent_performance_{timestamp}.csv", index=False)

    # Plot portfolio values over time
    plt.figure(figsize=(14, 7))
    for agent in agents:
        plt.plot(agent.history, label=agent.name)

    plt.title('Agent Portfolio Value Over Time')
    plt.xlabel('Trading Days')
    plt.ylabel('Portfolio Value (USD)')
    plt.legend()
    plt.grid(True)
    plt.savefig(f"{save_dir}/portfolio_values_{timestamp}.png", dpi=300)

    # Plot comparative performance metrics
    metrics_to_plot = ['growth_pct', 'max_drawdown_pct', 'sharpe_ratio', 'volatility']
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))

    for i, metric in enumerate(metrics_to_plot):
        ax = axes[i//2, i%2]
        agent_names = [agent.name for agent in agents]
        values = [agent.get_performance_metrics(prices)[metric] for agent in agents]
        ax.bar(agent_names, values)
        ax.set_title(f"{metric.replace('_', ' ').title()}")
        ax.grid(True, alpha=0.3)
        ax.tick_params(axis='x', rotation=45)

    plt.tight_layout()
    plt.savefig(f"{save_dir}/performance_metrics_{timestamp}.png", dpi=300)

    return results_df


def main():
    # File paths - replace with your actual paths
    data_file = "/content/LSTM_File_4ChainMetrics.csv"
    model_path = '/content/Bit_Coin_Price_Prediction_LSTM_Model_PriceUSD_Ver2.h5'
    scaler_X_path = '/content/btc_scaler_X_4ChainMetrics.pkl'
    scaler_y_path = '/content/btc_scaler_y_4ChainMetrics.pkl'

    # Config
    start_date = '2021-01-01'
    end_date = '2021-12-31'
    initial_cash = 100  # USD

    # Load data
    df = load_data(data_file, start_date, end_date)

    # Load models
    model, scaler_X, scaler_y = load_models(model_path, scaler_X_path, scaler_y_path)

    # Define feature columns to use
    feature_cols = ['PriceUSD', 'HashRate', 'TxTfrCnt', 'AdrActCnt', 'SplyCur']
    price_col = 'PriceUSD'

    # Initialize agents
    agents = [
        GreedyBuyer(name="GreedyBuyer", model=model, scaler_X=scaler_X, scaler_y=scaler_y, initial_cash=initial_cash),
        CautiousHolder(name="CautiousHolder", model=model, scaler_X=scaler_X, scaler_y=scaler_y, initial_cash=initial_cash),
        VolumeWeightedTrader(name="VolumeTrader", model=model, scaler_X=scaler_X, scaler_y=scaler_y, initial_cash=initial_cash)
    ]

    # Run simulation
    updated_agents, prices, dates = run_simulation(df, feature_cols, price_col, agents, time_steps=60)

    # Evaluate performance
    results = evaluate_performance(updated_agents, prices)

    # Display results
    plt.show()

    return results


if __name__ == "__main__":
    main()

# Predict
y_pred_scaled = model.predict(X_test)
y_pred = scaler_y.inverse_transform(y_pred_scaled).flatten()
y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()

actions = []

threshold_up = 0.003  # 0.3% increase = BUY
threshold_down = -0.003  # 0.3% decrease = SELL

for today_price, tomorrow_pred in zip(y_test_actual[:-1], y_pred[1:]):
    change = (tomorrow_pred - today_price) / today_price

    if change > threshold_up:
        actions.append('BUY')
    elif change < threshold_down:
        actions.append('SELL')
    else:
        actions.append('HOLD')

import matplotlib.pyplot as plt

# The fix: Use the same x-coordinates for buy and sell signals
buy_indices = [i for i, a in enumerate(actions) if a == 'BUY']
sell_indices = [i for i, a in enumerate(actions) if a == 'SELL']

plt.scatter(buy_indices, [y_test_actual[i] for i in buy_indices], label='BUY', marker='^', color='g')
plt.scatter(sell_indices, [y_test_actual[i] for i in sell_indices], label='SELL', marker='v', color='r')

plt.title('Buy/Sell/Hold Signals')
plt.xlabel('Time')
plt.ylabel('PriceUSD')
plt.legend()
plt.show()

def strategy_lstm(model, X_last_60, scaler_X, scaler_y):
    """Predict using your trained LSTM model"""
    pred_scaled = model.predict(X_last_60.reshape(1, *X_last_60.shape))
    pred = scaler_y.inverse_transform(pred_scaled).flatten()[0]
    current_price = scaler_y.inverse_transform(X_last_60[-1, 0].reshape(1, -1)).flatten()[0]  # Assuming PriceUSD is first feature
    change = (pred - current_price) / current_price
    if change > 0.003:
        return 'BUY'
    elif change < -0.003:
        return 'SELL'
    else:
        return 'HOLD'

def strategy_rsi(df):
    """Simple RSI Strategy"""
    rsi = df['RSI_14'].iloc[-1]
    if rsi < 30:
        return 'BUY'
    elif rsi > 70:
        return 'SELL'
    else:
        return 'HOLD'

def strategy_breakout(df):
    """Breakout Strategy"""
    recent_high = df['PriceUSD'].iloc[-20:].max()
    last_price = df['PriceUSD'].iloc[-1]
    if last_price > recent_high * 1.01:  # 1% above recent high
        return 'BUY'
    return 'HOLD'

# # Get the last 60 days of data (make sure to use all your features)
# last_60_days = df[['HashRate', 'TxTfrCnt', 'AdrActCnt', 'SplyCur', 'PriceUSD_target',
#                   'MA_7', 'MA_30', 'MA_7_30_ratio', 'Volatility_30']].tail(time_steps).values

# Get the last 60 days of data (make sure to use all your features)
last_60_days = df[['HashRate', 'TxTfrCnt', 'AdrActCnt', 'SplyCur', 'PriceUSD']].tail(time_steps).values

# Scale the data using your scaler_X
last_60_days_scaled = scaler_X.transform(last_60_days)

# Reshape for LSTM input (1 sample, 60 timesteps, n_features)
X_predict = last_60_days_scaled.reshape(1, time_steps, n_features)

# Make prediction
predicted_price_scaled = model.predict(X_predict)

# Inverse transform to get actual price
predicted_price = scaler_y.inverse_transform(predicted_price_scaled)

print(f"Predicted Bitcoin Price: ${predicted_price[0][0]:.2f}")

# Compare with the last known price
last_actual_price = df['PriceUSD_target'].iloc[-1]
print(f"Last Known Price: ${last_actual_price:.2f}")
print(f"Predicted Change: {((predicted_price[0][0] - last_actual_price) / last_actual_price * 100):.2f}%")

# Function to predict multiple days ahead
# CHANGES DAYS_AHEAD FROM 7 TO 120
def predict_future(days_ahead=120):
    # Start with the last known sequence
    current_sequence = df[['HashRate', 'TxTfrCnt', 'AdrActCnt', 'SplyCur', 'PriceUSD']].tail(time_steps).values

    current_sequence_scaled = scaler_X.transform(current_sequence)

    predictions = []

    for _ in range(days_ahead):
        # Reshape for prediction
        X_pred = current_sequence_scaled.reshape(1, time_steps, n_features)

        # Predict next price
        next_price_scaled = model.predict(X_pred, verbose=0)
        next_price = scaler_y.inverse_transform(next_price_scaled)[0][0]
        predictions.append(next_price)

        # Update sequence by adding the new prediction
        # This is a simplified approach - in reality you'd need to estimate other features too
        # new_row = current_sequence[-1].copy()
        # new_row[4] = scaler_y.inverse_transform(next_price_scaled)[0][0]  # Update PriceUSD_target
        # new_row = np.array([new_row])
        # new_row_scaled = scaler_X.transform(new_row)

        # Remove oldest day and add newest prediction
        # current_sequence_scaled = np.vstack([current_sequence_scaled[1:], new_row_scaled])

        # FIX: Replace the previous 3 lines with the following to update current_sequence directly:
        current_sequence = np.roll(current_sequence, -1, axis=0)  # Shift values up by one
        current_sequence[-1, 0] = next_price # Update the last element with the prediction
        current_sequence_scaled = scaler_X.transform(current_sequence)


    return predictions

# Predict prices for the next 60 days
future_prices = predict_future(60)
print("Predicted prices for the next 7 days:")
for i, price in enumerate(future_prices):
    print(f"Day {i+1}: ${price:.2f}")

# # Install the missing dependency
# %pip install tabulate

# Create a DataFrame for results
results_df = pd.DataFrame({
    'Metric': ['Total Data Points', 'Training Data Points', 'Testing Data Points',
               'RMSE', 'MAE', 'Directional Accuracy',
               'First Actual Price', 'First Predicted Price',
               'Last Actual Price', 'Last Predicted Price', 'Predicted Future Price'],
    'Value': [len(df), len(X_train), len(X_test),
              rmse, mae, dir_acc,
              y_test_actual[0][0], y_pred[0][0],
              y_test_actual[-1][0], y_pred[-1][0], predicted_price[0][0]]
})

# Display in markdown format
print(results_df.to_markdown(index=False))

# First, we need to generate future dates
# CHANGES:
# changing the period from 60 to 120
last_date = df['time'].iloc[-1]
future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=120, freq='D')

# Get future predictions (using the function from earlier)
future_predictions = predict_future(days_ahead=120)

# Plotting future predictions alongside actual prices
plt.figure(figsize=(14, 7))

# Get the actual dates for the test set
test_dates = df['time'].iloc[-len(y_test_actual):]

# Plot actual prices with dates
plt.plot(test_dates, y_test_actual, label='Actual Bitcoin Prices', color='blue')

# Plot predicted prices for test period
plt.plot(test_dates, y_pred, label='Predicted Bitcoin Prices', color='red')


# Future Predictions
plt.plot(future_dates, future_predictions, label='Future Predictions (Next 120 Days)',
         color='green', linestyle='--')

predicted_price = scaler_y.inverse_transform(predicted_price_scaled)

print(f"Predicted Bitcoin Price: ${predicted_price[0][0]:.2f}")

# Compare with the last known price
last_actual_price = df['PriceUSD_target'].iloc[-1]
print(f"Last Known Price: ${last_actual_price:.2f}")
print(f"Predicted Change: {((predicted_price[0][0] - last_actual_price) / last_actual_price * 100):.2f}%")

# Add a vertical line to mark where predictions start
plt.axvline(x=last_date, color='black', linestyle='-', alpha=0.3)
plt.text(last_date, plt.ylim()[1]*0.9, 'Prediction Start', rotation=90)

import pandas as pd
import numpy as np

# Make sure future_predictions is a 1D array or list
# If it's a nested list like [[x], [y], …], first unpack it:
if isinstance(future_predictions, list) and isinstance(future_predictions[0], (list, np.ndarray)):
    flat_preds = [p[0] for p in future_predictions]
else:
    flat_preds = np.array(future_predictions).reshape(-1)

# Build DataFrame
future_df = pd.DataFrame({
    'date': future_dates,
    'predicted_price_usd': flat_preds
})

# Save to CSV
future_df.to_csv('future_predictions.csv', index=False)
print("Saved future_predictions.csv!")


# Plotting
plt.title('Actual vs Predicted Bitcoin Prices with Future Predictions')
plt.xlabel('Date')
plt.ylabel('Price (USD)')
plt.legend()
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 'SplyCntCur' - this is for the supply count of the current coin
# 'CapMrktCurUSD' - this is for the market capitalization of the current coin
# 'PriceUSD' - this is for the price of the current coin
# 'TxTfrValAdjUSD' - this is for the adjusted transaction value in USD
# 'TxTfrValUSD' - this is for the transaction value in USD
# 'TxTfrCnt' - this is for the transaction count
# 'IssContNtv' - this is for the native issuance count
# 'IssContPctAnn' - this is for the annual percentage of the issuance count
#
# metrics = client.get_asset_metrics(assets='btc', metrics=['PriceUSD','HashRate','TxTfrCnt','AdrActCnt', 'SplyCur'], start_time="2013-01-01", end_time="2023-01-02", frequency='1d')
# metrics = client.get_asset_metrics(assets='btc', metrics=['PriceUSD','HashRate','TxTfrCnt','AdrActCnt', 'SplyCur'], start_time="2023-01-01", end_time="2024-01-02", frequency='1d')
metrics_eth = client.get_asset_metrics(assets='eth', metrics=['PriceUSD','HashRate','TxTfrCnt','AdrActCnt', 'SplyCur'], start_time="2017-01-01", end_time="2024-01-02", frequency='1d')

# Convert the DataCollection to a pandas DataFrame
metrics_eth = pd.DataFrame(metrics_eth)
metrics_eth['time'] = pd.to_datetime(metrics_eth['time'])
metrics_eth.sort_values('time', inplace=True)

# metrics_eth['TxTfrCnt'] = pd.to_numeric(metrics_eth['TxTfrCnt'], errors='coerce')
# metrics_eth['AdrActCnt'] = pd.to_numeric(metrics_eth['AdrActCnt'], errors='coerce')
# metrics_eth['SplyCur'] = pd.to_numeric(metrics_eth['SplyCur'], errors='coerce')
# metrics_eth['PriceUSD'] = pd.to_numeric(metrics_eth['PriceUSD'], errors='coerce')


# Create features
metrics_eth['PriceUSD_target'] = metrics_eth['PriceUSD'].shift(-1)
metrics_eth.dropna(inplace=True)

# Select same features used in training
# X = df[['HashRate','AdrActCnt', 'PriceUSD', 'TxTfrCnt_per_address', 'SplyCur_per_address']].values
X_eth = metrics_eth[['PriceUSD']].values
y_eth = metrics_eth['PriceUSD_target'].values

# Scale with the SAME scaler (important!)
X_eth_scaled = scaler_X.transform(X_eth)
y_eth_scaled = scaler_y.transform(y_eth.reshape(-1, 1))

time_steps = 60  # or whatever you used for Bitcoin

def create_sequences(X, y, time_steps=60):
    X_seq, y_seq = [], []
    for i in range(len(X) - time_steps):
        X_seq.append(X[i:i + time_steps])
        y_seq.append(y[i + time_steps])
    return np.array(X_seq), np.array(y_seq)

X_eth_seq, y_eth_seq = create_sequences(X_eth_scaled, y_eth_scaled, time_steps)

# Predict ETH using Bitcoin-trained model
y_pred_eth_scaled = model.predict(X_eth_seq)

# Inverse transform to get actual prices
y_pred_eth = scaler_y.inverse_transform(y_pred_eth_scaled)
y_eth_actual = scaler_y.inverse_transform(y_eth_seq.reshape(-1, 1))

# Calculate metrics
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

eth_rmse = np.sqrt(mean_squared_error(y_eth_actual, y_pred_eth))
eth_mae = mean_absolute_error(y_eth_actual, y_pred_eth)

print(f"ETH Testing RMSE: {eth_rmse:.2f}")
print(f"ETH Testing MAE: {eth_mae:.2f}")

# Predict ETH using Bitcoin-trained model
y_pred_eth_scaled = model.predict(X_eth_seq)

# Inverse transform to get actual prices
y_pred_eth = scaler_y.inverse_transform(y_pred_eth_scaled)
y_eth_actual = scaler_y.inverse_transform(y_eth_seq.reshape(-1, 1))

# Calculate metrics
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.dates import DateFormatter
import pandas as pd

eth_rmse = np.sqrt(mean_squared_error(y_eth_actual, y_pred_eth))
eth_mae = mean_absolute_error(y_eth_actual, y_pred_eth)
print(f"ETH Testing RMSE: {eth_rmse:.2f}")
print(f"ETH Testing MAE: {eth_mae:.2f}")

# Create date range for x-axis (if you have actual dates, use those instead)
# This assumes your test data represents consecutive days
# If you have actual dates in your DataFrame, use those instead
try:
    # Attempt to get actual dates if available in your data
    dates = eth_data.iloc[-len(y_eth_actual):]['time'].values
except:
    # If not available, create a date range
    dates = pd.date_range(end=pd.Timestamp.today(), periods=len(y_eth_actual))

# Create a visualization
plt.figure(figsize=(14, 7))

# Plot the actual and predicted prices
plt.plot(dates, y_eth_actual, label='Actual ETH Price', color='blue', linewidth=2)
plt.plot(dates, y_pred_eth, label='Predicted ETH Price', color='orange', linewidth=2, linestyle='--')

# Add a vertical line to indicate the end of training data if applicable
# plt.axvline(x=train_end_date, color='red', linestyle='-', alpha=0.3, label='Train-Test Split')

# Add graph elements
plt.title(f'Ethereum Price Prediction using Bitcoin-Trained Model\nRMSE: ${eth_rmse:.2f}, MAE: ${eth_mae:.2f}', fontsize=16)
plt.xlabel('Date', fontsize=14)
plt.ylabel('Price (USD)', fontsize=14)
plt.grid(True, alpha=0.3)
plt.legend(fontsize=12)

# Format the x-axis to show dates nicely
plt.gca().xaxis.set_major_formatter(DateFormatter('%Y-%m-%d'))
plt.xticks(rotation=45)

# Add annotations showing percentage error at a few points
n_points = 5  # Number of points to annotate
step = len(y_eth_actual) // (n_points + 1)
for i in range(step, len(y_eth_actual), step):
    error_pct = (y_pred_eth[i][0] - y_eth_actual[i][0]) / y_eth_actual[i][0] * 100
    plt.annotate(f'{error_pct:.1f}%',
                 xy=(dates[i], y_pred_eth[i][0]),
                 xytext=(10, 0), textcoords='offset points',
                 arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=.2'))

# Show the max and min prediction errors
max_error_idx = np.abs(y_pred_eth - y_eth_actual).argmax()
plt.scatter(dates[max_error_idx], y_pred_eth[max_error_idx], color='red', s=100, zorder=5)
plt.annotate(f'Max Error: ${abs(y_pred_eth[max_error_idx][0] - y_eth_actual[max_error_idx][0]):.2f}',
             xy=(dates[max_error_idx], y_pred_eth[max_error_idx]),
             xytext=(20, 20), textcoords='offset points',
             arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=.2'))

plt.tight_layout()
plt.savefig('eth_price_prediction.png', dpi=300)
plt.show()

# Additional plot: Error over time
plt.figure(figsize=(14, 5))
prediction_error = (y_pred_eth - y_eth_actual).reshape(-1)
plt.plot(dates, prediction_error, color='red', label='Prediction Error')
plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)
plt.fill_between(dates, prediction_error, 0, alpha=0.3, color='red' if np.mean(prediction_error) > 0 else 'green')
plt.title('Prediction Error Over Time (Actual - Predicted)', fontsize=16)
plt.xlabel('Date', fontsize=14)
plt.ylabel('Error (USD)', fontsize=14)
plt.grid(True, alpha=0.3)
plt.legend()
plt.gca().xaxis.set_major_formatter(DateFormatter('%Y-%m-%d'))
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('eth_prediction_error.png', dpi=300)
plt.show()

